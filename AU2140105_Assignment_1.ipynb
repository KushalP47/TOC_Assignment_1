{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import graphviz\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to read the NFA from input.txt file\n",
    "def read_nfa(input_file):\n",
    "    nfa = {\n",
    "        'states': set(),\n",
    "        'alphabet': set(),\n",
    "        'transitions': defaultdict(dict),\n",
    "        'start_state': None,\n",
    "        'accept_states': set()\n",
    "    }\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith(\"States:\"):\n",
    "                # Extract states from the line and remove brackets\n",
    "                nfa['states'] = set(line.split(\":\")[1].strip().strip('{}').split(\", \"))\n",
    "\n",
    "            elif line.startswith(\"Alphabet:\"):\n",
    "                # Extract alphabet from the line and remove brackets\n",
    "                nfa['alphabet'] = set(line.split(\":\")[1].strip().strip('{}').split(\", \"))\n",
    "\n",
    "            elif line.startswith(\"Start State:\"):\n",
    "                # Extract start state\n",
    "                nfa['start_state'] = line.split(\":\")[1].strip()\n",
    "\n",
    "            elif line.startswith(\"Accept States:\"):\n",
    "                # Extract accept states and remove brackets\n",
    "                nfa['accept_states'] = set(line.split(\":\")[1].strip().strip('{}').split(\", \"))\n",
    "\n",
    "            elif line.startswith(\"Transitions:\"):\n",
    "                # Now start reading the transitions in the format 'state -> symbol -> next_states'\n",
    "                for transition in file:\n",
    "                    transition = transition.strip()\n",
    "                    if \"->\" in transition:\n",
    "                        state, symbol, next_states = transition.split(\"->\")\n",
    "                        state = state.strip()\n",
    "                        symbol = symbol.strip()\n",
    "                        next_states = next_states.strip().split(\", \")\n",
    "\n",
    "                        # Add transitions to the NFA transition dictionary\n",
    "                        nfa['transitions'].setdefault(state, {}).setdefault(symbol, []).extend(next_states)\n",
    "    \n",
    "    return nfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "# Convert NFA to DFA using Powerset Construction Algorithm\n",
    "def convert_nfa_to_dfa(nfa):\n",
    "    dfa = {\n",
    "        'states': set(),\n",
    "        'alphabet': nfa['alphabet'],\n",
    "        'transitions': defaultdict(dict),\n",
    "        'start_state': None,\n",
    "        'accept_states': set()\n",
    "    }\n",
    "\n",
    "    # Start state of DFA is the epsilon closure of the NFA start state\n",
    "    start_state = frozenset([nfa['start_state']])\n",
    "    dfa['start_state'] = str(start_state)  # Convert to string for consistent use\n",
    "    dfa['states'].add(str(start_state))\n",
    "\n",
    "    # Queue to explore the DFA states\n",
    "    queue = deque([start_state])\n",
    "    visited = set([str(start_state)])\n",
    "\n",
    "    while queue:\n",
    "        current_dfa_state = queue.popleft()\n",
    "\n",
    "        for symbol in nfa['alphabet']:\n",
    "            next_nfa_states = set()\n",
    "            # Calculate the set of NFA states reachable from current_dfa_state on this symbol\n",
    "            for nfa_state in current_dfa_state:\n",
    "                if symbol in nfa['transitions'].get(nfa_state, {}):\n",
    "                    next_nfa_states.update(nfa['transitions'][nfa_state][symbol])\n",
    "\n",
    "            # Create the corresponding DFA state\n",
    "            next_dfa_state = frozenset(next_nfa_states)\n",
    "            next_dfa_state_str = str(next_dfa_state)  # Convert to string\n",
    "\n",
    "            if next_dfa_state:\n",
    "                dfa['transitions'][str(current_dfa_state)][symbol] = next_dfa_state_str\n",
    "                if next_dfa_state_str not in visited:\n",
    "                    visited.add(next_dfa_state_str)\n",
    "                    queue.append(next_dfa_state)\n",
    "                    dfa['states'].add(next_dfa_state_str)\n",
    "\n",
    "            # Check if the new DFA state is an accept state\n",
    "            if any(state in nfa['accept_states'] for state in next_nfa_states):\n",
    "                dfa['accept_states'].add(next_dfa_state_str)\n",
    "\n",
    "    return dfa\n",
    "\n",
    "\n",
    "def minimize_dfa(dfa):\n",
    "    # Step 1: Initialize partitions\n",
    "    P = [dfa['accept_states'], dfa['states'] - dfa['accept_states']]\n",
    "    W = [dfa['accept_states'].copy()]  # States that need to be split\n",
    "\n",
    "    # Step 2: Refining partitions\n",
    "    while W:\n",
    "        A = W.pop()\n",
    "\n",
    "        for symbol in dfa['alphabet']:\n",
    "            # Get all states that transition on 'symbol' to a state in 'A'\n",
    "            X = {state for state in dfa['states'] if symbol in dfa['transitions'].get(state, {}) and dfa['transitions'][state][symbol] in A}\n",
    "\n",
    "            for Y in P[:]:\n",
    "                intersection = Y & X\n",
    "                difference = Y - X\n",
    "\n",
    "                if intersection and difference:\n",
    "                    # Replace Y in P with two sets: intersection and difference\n",
    "                    P.remove(Y)\n",
    "                    P.append(intersection)\n",
    "                    P.append(difference)\n",
    "\n",
    "                    # Add the smaller of the two to W\n",
    "                    if intersection in W:\n",
    "                        W.append(difference)\n",
    "                    else:\n",
    "                        W.append(intersection)\n",
    "\n",
    "    # Step 3: Create the minimized DFA\n",
    "    minimized_dfa = {\n",
    "        'states': set(),\n",
    "        'alphabet': dfa['alphabet'],\n",
    "        'transitions': defaultdict(dict),\n",
    "        'start_state': None,\n",
    "        'accept_states': set()\n",
    "    }\n",
    "\n",
    "    # Map old states to new states (partition groups)\n",
    "    state_map = {}\n",
    "    for partition in P:\n",
    "        new_state = str(frozenset(partition))  # Convert to string\n",
    "        minimized_dfa['states'].add(new_state)\n",
    "\n",
    "        for state in partition:\n",
    "            state_map[state] = new_state\n",
    "            if state == dfa['start_state']:\n",
    "                minimized_dfa['start_state'] = new_state\n",
    "            if state in dfa['accept_states']:\n",
    "                minimized_dfa['accept_states'].add(new_state)\n",
    "\n",
    "    # Define transitions for minimized DFA\n",
    "    for old_state, transitions in dfa['transitions'].items():\n",
    "        new_state = state_map[old_state]\n",
    "        for symbol, next_old_state in transitions.items():\n",
    "            minimized_dfa['transitions'][new_state][symbol] = state_map[next_old_state]\n",
    "\n",
    "    return minimized_dfa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def generate_graph(automaton, output_file):\n",
    "    dot = graphviz.Digraph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for state in automaton.get('states', []):\n",
    "        if state in automaton.get('accept_states', []):\n",
    "            dot.node(state, shape='doublecircle')\n",
    "        else:\n",
    "            dot.node(state, shape='circle')\n",
    "    \n",
    "    # Create edges\n",
    "    for state, transitions in automaton.get('transitions', {}).items():\n",
    "        for symbol, next_states in transitions.items():\n",
    "            for next_state in next_states:\n",
    "                dot.edge(state, next_state, label=symbol)\n",
    "    \n",
    "    # Render the graph to a file\n",
    "    dot.render(output_file, format='png', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testcases/testcase-3...\n",
      "Processing testcases/testcase-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.967177 to fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testcases/testcase-1...\n"
     ]
    }
   ],
   "source": [
    "# Main function to process each test case\n",
    "def process_testcase(testcase_dir):\n",
    "    input_file = os.path.join(testcase_dir, 'input.txt')\n",
    "    dfa_output_file = os.path.join(testcase_dir, 'dfa_image')\n",
    "    minimized_dfa_output_file = os.path.join(testcase_dir, 'minimized_dfa_image')\n",
    "\n",
    "    # Read NFA from input.txt\n",
    "    nfa = read_nfa(input_file)\n",
    "    \n",
    "    # Convert NFA to DFA\n",
    "    dfa = convert_nfa_to_dfa(nfa)\n",
    "    \n",
    "    # Generate DFA graph image\n",
    "    generate_graph(dfa, dfa_output_file)\n",
    "\n",
    "    # Minimize DFA\n",
    "    minimized_dfa = minimize_dfa(dfa)\n",
    "    \n",
    "    # Generate minimized DFA graph image\n",
    "    generate_graph(minimized_dfa, minimized_dfa_output_file)\n",
    "\n",
    "# Loop through each test case folder and process\n",
    "def process_all_testcases(testcases_root):\n",
    "    for testcase in os.listdir(testcases_root):\n",
    "        testcase_dir = os.path.join(testcases_root, testcase)\n",
    "        if os.path.isdir(testcase_dir):\n",
    "            print(f\"Processing {testcase_dir}...\")\n",
    "            process_testcase(testcase_dir)\n",
    "\n",
    "# Run the script for all test cases\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_testcases('testcases')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
